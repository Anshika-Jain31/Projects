{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df880262-9d7d-4aa5-a8eb-93036a647355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI #OpenAI --create a client object to communicate with OpenAI's API in the newer SDK\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5382b8c3-4777-4306-a48c-f1e7591deec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env and API key\n",
    "load_dotenv(\"env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19efd80b-ed07-4307-bace-4b56236e0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client (✅ REQUIRED in new SDK)\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d16e59d-fa82-4037-8f74-7c320a2fcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define function to chat with AI\n",
    "def chat_with_ai(user_input):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  \n",
    "        messages= [\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        temperature=1.0,     # <--- Controls randomness\n",
    "        max_tokens=100       # <--- Limits the length of the response\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b4f2f3-d710-4685-bffc-6a0dd2e138f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define function to chat with AI\n",
    "def chat_with_ai(user_input):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  \n",
    "        messages= [\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        temperature=1.0,     # <--- Controls randomness\n",
    "        max_tokens=100       # <--- Limits the length of the response\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242db1b4-e882-4d5e-a022-1f9c5cd1ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I’m your virtual assistant. Ask me anything!\n",
      "Type 'bye' or 'exit' to end the chat.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Start a loop to keep chatting\n",
    "print(\"Hi! I’m your virtual assistant. Ask me anything!\")\n",
    "print(\"Type 'bye' or 'exit' to end the chat.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78fee823-a4df-4b38-b0a8-8f0ebc9bed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hii\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ChatCompletion(id='chatcmpl-BmInpefAkM4Zg00eaZDVqexlNgC9V', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1750851721, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=9, total_tokens=18, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take care! Your assistant is signing off.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == \"exit\" or user_input.lower() == \"bye\":\n",
    "        print(\"Take care! Your assistant is signing off.\")\n",
    "        break\n",
    "    \n",
    "    ai_reply = chat_with_ai(user_input)\n",
    "    print(\"AI:\", ai_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04696bc-6f89-4fcd-b674-64efcafcd4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newkernel",
   "language": "python",
   "name": "newkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
